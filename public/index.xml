<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Aaron&#39;s D4ta blog</title>
    <link>https://drwaterx.github.io/til/</link>
    <description>Recent content on Aaron&#39;s D4ta blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 08 Jan 2023 15:18:18 -0500</lastBuildDate><atom:link href="https://drwaterx.github.io/til/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Explainable insights from linear regression of time series</title>
      <link>https://drwaterx.github.io/til/posts/practical_primer_ts/</link>
      <pubDate>Sun, 08 Jan 2023 15:18:18 -0500</pubDate>
      
      <guid>https://drwaterx.github.io/til/posts/practical_primer_ts/</guid>
      <description>This post is under construction, with missing graphs and unbaked LaTax math.
It&amp;rsquo;s a cliche that linear models are &amp;ldquo;explainable.&amp;rdquo; And yet, when we attempt to produce insights that are salient to business, and produce them from the kind of data representing, let&amp;rsquo;s say, tens of thousands of cases, you will quickly find characteristics of the data that appreciably erode the veracity and salience of supposed insights.
This is especially the case when applying canned routines in general, and I&amp;rsquo;ve found, time series &amp;lsquo;forecasting&amp;rsquo; packages in particular.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://drwaterx.github.io/til/about/</link>
      <pubDate>Sun, 08 Jan 2023 10:43:15 -0500</pubDate>
      
      <guid>https://drwaterx.github.io/til/about/</guid>
      <description>Today I learned something, and I learned it because I wrote about it to uncover what I still need to learn. And I&amp;rsquo;m sharing it with you for no other reason than it may be helpful for you to retrace the steps of my thought process, compare it to your own, and reach your own understanding.
That retreading has been helpful to me.
What I write about are solutions to problems I confront in my job, which at the moment involves processing and modeling commercial cash flows.</description>
    </item>
    
    <item>
      <title>Handle non-sensical operations to avoid downstream errors</title>
      <link>https://drwaterx.github.io/til/posts/numpy_nonsense/</link>
      <pubDate>Thu, 05 Jan 2023 05:15:02 -0500</pubDate>
      
      <guid>https://drwaterx.github.io/til/posts/numpy_nonsense/</guid>
      <description>When attempting to log-transform an array of values with NumPy, keep in mind
Given negative numbers and zeroes, NumPy will output NaN and -inf, respectively, along with a RuntimeWarning. Such values can cause downstream processing to fail or behave unexpectedly. numpy.log provides an argument to handle this situation How that argument affects numpy.log&amp;rsquo;s behavior depends on whether the output goes to a preexisting container or if that container is created on the fly.</description>
    </item>
    
    <item>
      <title>Slice well</title>
      <link>https://drwaterx.github.io/til/posts/slices_awry/</link>
      <pubDate>Tue, 15 Nov 2022 11:21:31 -0500</pubDate>
      
      <guid>https://drwaterx.github.io/til/posts/slices_awry/</guid>
      <description>In this post, I briefly review a few methods to select rows and/or columns of a DataFrame that satisfy one or more criteria. I then introduce two additional requirements that arises frequently in practice&amp;ndash;slicing with previously unknown criteria and managing serialization and deserialization to recover the desired data structure.
Lever multiIndexes I often find pandas&amp;rsquo; multiIndex to be helpful, although I do not observe it used very often. With a multi-indexed DataFrame, pandas&amp;rsquo; .</description>
    </item>
    
    <item>
      <title>That which is aggregated and its metadata</title>
      <link>https://drwaterx.github.io/til/posts/gbadventures01/</link>
      <pubDate>Fri, 12 Aug 2022 15:14:44 -0500</pubDate>
      
      <guid>https://drwaterx.github.io/til/posts/gbadventures01/</guid>
      <description>It&amp;rsquo;s impossible to include an associated field value alongside an aggregate of another variable Unlike ndarrays, DataFrames are often heterogeneous. They are a more complete map of how we think of a data set as a whole. When we alter the structure of tabular data, often through aggregation of one field, we want to include values from other fields. This is an example of an issue that arises at the interface of pandas and scikit-learn, for which the ColumnTransformer was created.</description>
    </item>
    
    <item>
      <title>Aggregation: Implications of indexing</title>
      <link>https://drwaterx.github.io/til/posts/gbadventures02/</link>
      <pubDate>Fri, 22 Jul 2022 14:34:27 -0500</pubDate>
      
      <guid>https://drwaterx.github.io/til/posts/gbadventures02/</guid>
      <description>While there are multiple syntaxes and methods to produce the same aggregated data, those variations produce different indices. The format and contents of the index can impact other processes, such as serialization and deserialization.
Consider the following artificial transactional data.
txns = pd.concat([pd.DataFrame({&amp;#39;dt&amp;#39;: pd.date_range(&amp;#34;2022&amp;#34;, freq=&amp;#34;D&amp;#34;, periods=10), &amp;#39;amount&amp;#39;: np.random.random(10), &amp;#39;segment&amp;#39;: [&amp;#39;ex&amp;#39;] * 10})] * 10, axis=0) dt amount segment (Timestamp(&amp;lsquo;2022-01-01 00:00:00&amp;rsquo;), 0) 2022-01-01 00:00:00 0.992821 ex (Timestamp(&amp;lsquo;2022-01-01 00:00:00&amp;rsquo;), 0) 2022-01-01 00:00:00 0.</description>
    </item>
    
  </channel>
</rss>
