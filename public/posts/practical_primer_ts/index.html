<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Explainable insights from linear regression of time series | Aaron&#39;s D4ta blog</title>
<meta name="keywords" content="modeling, statsmodels">
<meta name="description" content="This post is under construction, with missing graphs and unbaked LaTax math.
It&rsquo;s a cliche that linear models are &ldquo;explainable.&rdquo; And yet, when we attempt to produce insights that are salient to business, and produce them from the kind of data representing, let&rsquo;s say, tens of thousands of cases, you will quickly find characteristics of the data that appreciably erode the veracity and salience of supposed insights.
This is especially the case when applying canned routines in general, and I&rsquo;ve found, time series &lsquo;forecasting&rsquo; packages in particular.">
<meta name="author" content="Aaron Slowey">
<link rel="canonical" href="https://drwaterx.github.io/til/posts/practical_primer_ts/">
<link crossorigin="anonymous" href="/til/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css" integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/til/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://drwaterx.github.io/til/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://drwaterx.github.io/til/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://drwaterx.github.io/til/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://drwaterx.github.io/til/apple-touch-icon.png">
<link rel="mask-icon" href="https://drwaterx.github.io/til/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>


<meta property="og:title" content="Explainable insights from linear regression of time series" />
<meta property="og:description" content="This post is under construction, with missing graphs and unbaked LaTax math.
It&rsquo;s a cliche that linear models are &ldquo;explainable.&rdquo; And yet, when we attempt to produce insights that are salient to business, and produce them from the kind of data representing, let&rsquo;s say, tens of thousands of cases, you will quickly find characteristics of the data that appreciably erode the veracity and salience of supposed insights.
This is especially the case when applying canned routines in general, and I&rsquo;ve found, time series &lsquo;forecasting&rsquo; packages in particular." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://drwaterx.github.io/til/posts/practical_primer_ts/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-08T15:18:18-05:00" />
<meta property="article:modified_time" content="2023-01-08T15:18:18-05:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Explainable insights from linear regression of time series"/>
<meta name="twitter:description" content="This post is under construction, with missing graphs and unbaked LaTax math.
It&rsquo;s a cliche that linear models are &ldquo;explainable.&rdquo; And yet, when we attempt to produce insights that are salient to business, and produce them from the kind of data representing, let&rsquo;s say, tens of thousands of cases, you will quickly find characteristics of the data that appreciably erode the veracity and salience of supposed insights.
This is especially the case when applying canned routines in general, and I&rsquo;ve found, time series &lsquo;forecasting&rsquo; packages in particular."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://drwaterx.github.io/til/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Explainable insights from linear regression of time series",
      "item": "https://drwaterx.github.io/til/posts/practical_primer_ts/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Explainable insights from linear regression of time series",
  "name": "Explainable insights from linear regression of time series",
  "description": "This post is under construction, with missing graphs and unbaked LaTax math.\nIt\u0026rsquo;s a cliche that linear models are \u0026ldquo;explainable.\u0026rdquo; And yet, when we attempt to produce insights that are salient to business, and produce them from the kind of data representing, let\u0026rsquo;s say, tens of thousands of cases, you will quickly find characteristics of the data that appreciably erode the veracity and salience of supposed insights.\nThis is especially the case when applying canned routines in general, and I\u0026rsquo;ve found, time series \u0026lsquo;forecasting\u0026rsquo; packages in particular.",
  "keywords": [
    "modeling", "statsmodels"
  ],
  "articleBody": "This post is under construction, with missing graphs and unbaked LaTax math.\nIt’s a cliche that linear models are “explainable.” And yet, when we attempt to produce insights that are salient to business, and produce them from the kind of data representing, let’s say, tens of thousands of cases, you will quickly find characteristics of the data that appreciably erode the veracity and salience of supposed insights.\nThis is especially the case when applying canned routines in general, and I’ve found, time series ‘forecasting’ packages in particular. At no fault of their developers, such packages are riddled with potential user missteps, since they abstract away a lot of the details of how data are prepared for modeling. The fidelity between the temporal structure of the time series and the parameters of the model are one of the more reliable missteps one can take.\nPackages like statsmodels. tsa are workhorses, but do not check, for instance, whether a daily time series contains only business days, while the user has specified a ‘seasonality’ period of 7. But when I started using it, I was not sure if it did or not, and so I created artificial data with known structural infidelities and effects and observed how statsmodels responded, and what distortions ensued. This post is a recounting of some of those experiments.\nThe following covers mostly in-sample deconstruction of temporally sensitive effects that can be applied to a variety of problems, including forecasting. I mention this because in my work at least, the goal is not just to predict the future but understand temporal patterns and relationships, since capacity is inextricably linked to maintenance costs, failure risk, and other things that really matter in business.\nWe denote a time series context with some additional subscripts: $$y_t = \\alpha + \\sum_{i=1}^m \\beta_i x_{i,t} + \\epsilon_t$$ The properties of variables that constitute $x$ determine what kind of time series regression we perform.\nAn auto-regression model includes up to $p$ lags: $x_{t-p}, \\ldots, x_{t-1}$ A linear trend is included by $x_{1, t} = t$; assuming equally spaced observations, $t$ would be np.linspace(1, T) Day of week is achieved by having one binary variable for all but one day; i.e., $x_{i, t}=1$ if the observation occurs on a particular day and zero otherwise. For any categorical variable having $k$ unique values, include $k-1$ binary variables into the model. So if we leave out Sunday, $x_{Monday, t}$ measures the effect of Monday on $y$ compared to the effect of Sunday. Spike: A dummy variable that is 1 in a specific period, zero before and after Step: A dummy variable zero up to a point, 1 from that point on. Related is a change in slope. As with OLS, you can apply statsmodels’ .summary() method to the fitted model object, as well as .plot_predict(start=720, end=840).\nThe ’errors’ should\nHave mean zero Not be auto-, or serially, correlated; Breusch-Godfrey or Lagrange Multiplier test, in which a small p-value is bad (significant autocorrelation remains). Unrelated to the predictors Be normally distributed with a constant variance .plot_diagnostics() provides some of these diagnostics.\nstatsmodels.tsa has multiple methods for time series analysis/regression/forecasting. Each term has a different connotation, depending on how you deploy them. We do not have to use .tsa methods to model sequence data; multivariate linear regression with univariate lags and time characteristic variables could achieve roughly the same model. A variety of considerations may determine the choice of model class, such as simply being able to report that you used a certain time series analysis package.\nIn any case, we are tackling the challenge of building a linear model with familiar performance criteria. The most profound difference is that the observations are possibly auto-correlated, not I.I.D., but this may ’normalize’ out by simply including lags and time characteristics (seasonal components).\nA good starting point is the AutoReg class of statsmodels.tsa.ar_model.\nfrom statsmodels.tsa.api import acf, graphics, pacf from statsmodels.tsa.ar_model import AutoReg, ar_select_order auto_reg = AutoReg(data, lags=3, # AR(3) seasonal=True, period=7, ) auto_reg0 = auto_reg.fit() Worked example in the statsmodels documentation that fails to clearly show how each component manifests, and exactly what parameters affect the fit. That ambiguity ends here.\nAn overarching question is – to what extent do statsmodels implementations include utilities that recognize and utilize datetimes? The work below suggests not at all, despite some warning or errors when seasonal=True, but period is unspecified. To obtain expected behavior from statistical learning algorithms, it is crucial to know and potentially modify the sequential structure (spacing) of data, because there do not appear to be intelligent checks and automated cleaning processes. Other key questions include\nFor example, $m=52$, unless tsa interprets datetime values intelligently, only implies a weekly periodicity if there are $7\\cdot52$ rows of data. What if we have $T=1.5$ years of data; haven’t seen any caution to carefully compute the period as $m=p\\cdot\\frac{52}{q} \\cdot T$, where p and q define the period of interest There are a few days missing? What if the data lack Saturdays and Sundays, as with BOLT data? Does the data need to be processed to ensure there are 7 days per week, 52 weeks per year, imputing zeroes where needed? To begin, create artificial data with known patterns. Create one year of daily timestamps and initialize the observations with random numbers $\\in (0, 1)$. For other possibilities, see also sklego.datasets.make_simpleseries.\nfrom statsmodels.tsa.ar_model import AutoReg, ar_select_order days = np.arange('2022-01-01', '2023-01-01', dtype='datetime64[D]') print( f'There are {len(days)} days in the year 2022 (start {days.min()}; end {days.max()}).') ts = pd.DataFrame({'t': days, # np.linspace(1, 100, 100) 'y': np.random.random(len(days))} ) ![[professional/know_how/stat_modeling/attachments/visualization.png]]\nEncode a time characteristic, such as day of the week (dow) and boost the signal on certain days (or weeks, etc.). Here, we spike the signal on Fridays. Then we play with the seasonal and period parameters.\nts.loc[:, 'dow'] = ts.t.dt.weekday ts.y = ts.y + np.where(ts.dow == 4, 2, 0) auto_reg = AutoReg(ts.y, lags=4, trend='t', seasonal=False, period=7, ) auto_reg0 = auto_reg.fit() ts.loc[:, 'y_hat'] = auto_reg0.predict() c2 = altair_ts_line(ts, 't', 'y_hat', 't') (c0 + c2).add_selection(pan_zoom) With seasonal=False, we obtain an upwardly trending oscillation: ![[professional/know_how/stat_modeling/attachments/visualization (1).png]]\nEnable seasonal, and we get the expected level baseline with weekly peaks: Exhibit A ![[professional/know_how/stat_modeling/attachments/visualization (2).png]]\nIf we set period=365, we get a ValueError: The model specification cannot be estimated. The model contains 370 regressors (1 trend, 365 seasonal, 4 lags) but after adjustment for hold_back and creation of the lags, there are only 361 data points available to estimate parameters.\nAnd if we set to a feasible, but wrong value – period=30 – we will get a somewhat better result, than without any periodicity, but clearly missing the effect: ![[professional/know_how/stat_modeling/attachments/visualization (4).png]]\nInterestingly, if we increase lags=7 to include the weekly effect, we get almost as good a model as with seasonal terms:\nauto_reg = AutoReg(ts.y, lags=7, trend='t', seasonal=False, period=7) ![[professional/know_how/stat_modeling/attachments/visualization (5).png]]\nAny number of lags above seven, and we see no improvement. Although not shown, the model with lags=7 and seasonal=True with period=7 looks identical to the seasonal=True, period=7 model with lags=4 above, suggesting that the $x_{t-p}$ and $s_d$ terms are collinear.\nstatsmodels.tsa.ar_model.AutoReg interprets period=7 as the longest step from one data point to the next in the dataframe; shorter steps from 1 to $p-1$ are also included. We think that something happens every 7th observation in the sequence, and whether we like it or not, AutoReg checks whether anything happens on shorter cadences. As discussed in detail below, whether those steps correspond to a meaningful time interval or period depends on the structure of the sequence.\nLook at the coefficients by applying the .params method to the fitted model object; e.g., with lags=2, seasonal=True, and period=7: ![[Pasted image 20221003171824.png]]\nNote that with period and lags set to an integer, multiple terms are included up to that value: e.g., $[1, \\text{lags}]$. Unlike period, you may provide a list of integers for lags, in which case only those lags are included. As expected, we find seasonal.6 coefficient to be much higher than those of narrower periodicities. It’s also no accident that seasonal components 0-5’s coefficients are similar to each other. We will investigate how this model responds to data with multiple periodicities.\nContinuing on with sanity checks, no matter the length of the sequence, as long as there are more data points than lags (and other parameters), the model will fit properly. Here, we have data from Jan through March 2022. ![[visualization (6).png]]\nstatsmodels.tsa does not require the time or sequence index to be of a datetime dtype. Replacing datetime values by integers, we obtain the same result (not shown). But note that AutoReg is not being explicitly given a sequence or time variable; it is implicit in the pandas.Series index of ts.y , so the algorithm is unaware of the change in the time column ts.t . If we remove a small number of points at random such that there are gaps in the index, the model falls apart (not shown). Can we make the seasonal regression algorithm aware that observations are made on calendar days?\npoints = 5 idx_mask = np.random.randint(0, len(ts), points) ts = ts[~ts.index.isin(idx_mask)] Incidentally, avoid df.sample(frac=0.9), as it shuffles the rows.\nSetting the index with the datetime-formatted values (maintaining the five randomly placed gaps) leads to ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting. The predictions from .predict() are all null.\nWhat matters is a logical correspondence between period and the frequency of the data as presented by their sequence in the array or DataFrame. Let’s say period=7; if the frequency is unspecified, the algorithm just considers if a data point six steps from the current point tends to be higher, lower, or about the same as the current point. If the data happen to be observations recorded every nanosecond with a perturbation every 13 ns, period=13 should fit that sequence nicely. This naive behavior is helpful for modeling observations that occur with a regularity that is meaningful, if not in a temporal way. For example, every fourth trip to buy groceries, the family goes to Costco, not Trader Joe’s. But it poses a problem for incomplete and irregular sequences when effects pertain to certain fixed time qualities.\nWhen .set_index('dt_col') involves a datetime column, we obtain a DateTimeIndex with freq=None, which statsmodels.tsa.ar_model is complaining about. We can specify the frequency\nts = ts.set_index('t').asfreq('d') Having reproduced the result shown in Exhibit A with a complete data set indexed in this way, we return to the case where points are randomly missing; remove them prior to setting the datetime index and frequency. Here, we introduce a potential problem. As an aside, .asfreq('B') sets an index to daily business day. More .asfreq can be applied to a DataFrame; it will return the DataFrame “reindexed to the specified frequency.” Meaning the “original data conformed to a new index with the specified frequency.” In this case, to conform to daily frequency, rows of nan are placed where time points were missing. Before and after applying .asfreq('d'): ![[Pasted image 20221004101943.png]] ![[Pasted image 20221004102013.png]]\nAutoReg will raise a MissingDataError: exog contains inf or nans, resolvable by including missing='drop'. And yet even though we have a DatetimeIndex with freq='D', we still get a ValueWarning: A date index has been provided, but it has no associated frequency information . Instead of a DatetimeIndex with .asfreq('d'), we can try a PeriodIndex, a subclass of Index that is regularly spaced:\nts.set_index('t', inplace=True) ts.index = pd.DatetimeIndex(ts.index).to_period('D') PeriodIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-08', '2022-01-09', '2022-01-10', ... '2022-12-22', '2022-12-23', '2022-12-24', '2022-12-25', '2022-12-26', '2022-12-27', '2022-12-28', '2022-12-29', '2022-12-30', '2022-12-31'], dtype='period[D]', name='t', length=360, freq='D') We still have gaps in the time series, but no nan have been inserted: ![[Pasted image 20221004104608.png]]\nIt is unnecessary to include missing='drop' in AutoReg(), since the data has no missing values (it is probably good practice to include missing='raise' as a check). .fit() runs and .predict() returns values without alterring the input data structure: it still has a PeriodIndex: ![[Pasted image 20221004105317.png]]\nDid the model fit well? While the PeriodIndex facilitated the fit, it complicates plotting with Altair. Assuming the index needs to be reset into a column, a PeriodIndex resets to a column of 'period[D]' dtype, and this leads to a TypeError. After fitting the model with PeriodIndex-ed data, reformat the index:\nts.index = ts.index.to_timestamp() You will lose the freq and have a DatetimeIndex once again. Then reset _ that_ index and plot as usual. ![[professional/know_how/stat_modeling/attachments/visualization (2) 1.png]] ![[Pasted image 20221004121816.png]] Our model did not capture the Friday signal as before, presumably because it naively assumed every $7\\cdot n^{th}$ point was Friday, ignoring the days skipped in the index. Note how the parameters’ seasonal components are written as s(1, 7), whereas before it was seasonal.0. The connotation is that we’re capturing effects that occur every 1st of 7 days?\nWe’ve tried two ways to structure our data such that statsmodels.tsa is aware of timing. But this data transformation did not apparently raise such awareness, as the model failed to fit the elevated values on Fridays. It could not even use the DateTimeIndex with a daily frequency. All of these observations suggest that what ultimately matters to statsmodels.tsa is the numerical index of the table; row 6 means Friday, whether the Tuesday before is missing or not (in which case Friday is actually in row 5). To the machine, they are all just row indices, not days.\nNotice how the model suggests a stronger signal around day 7, adjoined by expectation of signal quite a bit before; the behavior is smeared or muddled. Absence of even a handful of time points throws off the periodicity of this time series.\nAs for the datetime, period, and all that functionality in pandas…it serves other uses, such as resampling, aggregations, synthesizing data, and more.\nThis is a practical problem, as there are bound to be missing time points, either random or systematic (e.g., transactions on business days only). A path forward would be to have all dates present and put zeroes where no transactions occurred (perhaps packages like tbats do this under the hood?). For some systematic effects like weekend dormancy, the model should fit coefficients on those days accordingly; i.e., $\\beta_{s(5)}$ and $\\beta_{s(6)}$ should be close to zero. Holidays are another systematic effect we would need an exogenous binary variable to capture to avoid errors in the seasonal component estimates. Lastly, randomly occurring times without transactions will just have to be factored in by $\\beta_{s(t)}$ to the extent they occur, which is rational.\nUsing .asfreq to conform a daily time series of 365 points minus 10 removed at random to a DatetimeIndex-ed dataframe with freq='D', we get a good fit.\nts = ts.asfreq('d') ts.fillna(0, inplace=True) auto_reg = AutoReg(ts.y, missing='raise', lags=2, trend='t', seasonal=True, period=7, old_names=False, ) auto_reg0 = auto_reg.fit() ts.loc[:, 'y_hat'] = auto_reg0.predict() ![[Pasted image 20221004163931.png]]\nThe coefficient 2.37 is lower than 2.55 for the fit of the complete dataset, which suggests that some Fridays may have been zeroed out by the data preparation. But as long as such a random effect is not too prevalent, the autoregression should provide reasonable results. Here the incidence of ' missing’ days is about 3%.\nAnother method may allow discrete seasonality, rather than the inclusive/cumulative sort employed by AutoReg. The choice calls for a design principle:\nAutoregression plus seasonality Hand-derived features Both: what are each capturing? For example, no matter how many time points are absent, if we encode Friday correctly, that feature will light up on this artificial data set, and so is a more reliable approach than an autoregressive seasonality model (alone). Since it cannot include custom features, the AutoReg class is more suitable for EDA than deployment as an estimator or forecasting service.\nNo matter what method we choose, we need to verify, using synthetic data, that the choice and its parameters is congruent with the structure of our sequence data.\nWhat if the signal boost occurred every other Friday? s(7,7) = 1.5, while other seasonal variables are similar to before, although a bit elevated (0.51 to 0.56); what seems to have happened is a halving of the Friday effect. The model is unaware of what week each transaction occurred. ![[visualization (8).png]]\nIncreasing period to 15 leads to worse results, probably due to how larger interval effects do not consistently align to even or odd Fridays across months of the year. In sum, if we believe such specific periodic effects are there, or conversely want to probe for them, we should simply encode it as a binary variable consistent with how the data are prepared. The coefficients on those variables from the regression provide the evidence. From there, we can decide whether to remove extraneous variables, to improve our estimates of the remaining effects. To probe for suprises in production, we may deploy the more inclusive, though, problematic (collinearity, etc.) alongside the ‘selected’ model.\nUp until this point, binary variables and periodic components in the AutoReg model class produce spiky or jagged looking forecasts. The variability common to real world data–a recurring transaction happening around, rather than consistently precisely on, a particular day, attenuates the weight ( coefficient) of the effect(s), as it should. However, the attenuation may be unpredictably unstable, because we’re asking the model to size a discrete effect that may never exist. Instead, we can relax the effect to have some flexibility–a day or two before or after Friday, for instance. We just need to change the Dirac deltas to humps, or radial basis functions.\nIn a 2018 Pydata London talk, Vincent Warmerdam spoke about linear models, including using RBFs. See also his talk How to Constrain Artificial Stupidity . He has co-led initiatives including evol and scikit-lego.\nMost web searches go to RBF kernels for SVMs or RBF neural networks, neither of which are tactically relevant here. SciPy has an RBF fitting routine; closer perhaps, but still not in-line with our objective to produce artificial peaks as regression predictors; that is, to generate artificial peaks and let the regression weigh its importance and tune their widths, given the presence of other behaviorally (temporally) specific effects on the RHS. The math that fulfills this purpose is $$\\phi(x_i) = \\text{exp} \\Big[-\\frac{1}{2\\alpha} (x-m_i)^2 \\Big]~ \\forall ~\\text{week, month, or} \\dots$$ where $$ m_i=\\begin{cases} 1, \u0026 \\text{if}\\ x ~ \\text{mod}~ im_1=0 \\ 0, \u0026 \\text{otherwise} \\end{cases} $$ and $i$ ranges from 1 to however many instances of period $m_1$ exist in the data; for instance, if $m_1=7$, and we have 56 days of data, $i\\in[1, 2, 3, 4,5 ,6, 7, 8]$ and $m \\in [7, 14, 21, 28, 35, 42, 49, 56]$. Recall the $\\text{mod}$, or modulo, is the remainder that, alongside the _ quotient_, is an answer to a division of a dividend by a divisor. For example, 14 mod 3 = 2; 9 mod 3 and 121 mod 11 are zero.\nNote $m$ is the period as defined in relation to the sequence structure; e.g., 7 implies weekly periodicity if data are daily; 6 would imply a semiannual periodicity of monthly data and annual periodicity for bimonthly data.\nThe RBF should\nPeak at 1 at the characteristic points in the sequence and Smoothly decay to zero on either side. The exponential will only evaluate to 1 when the quantity in the brackets is zero; i.e., when $x = m_i$; $i$ denotes the $i^{\\text{th}}$ week, month, etc. within the data’s boundaries. For weekly periodicity, the RBF evaluates to 1 when $x \\in [7, 14, 21, …]$. While it is easy to perform this calculation for one value of $m$ (see below), to get the other humps we need, we need to also subtract 14 and so on.\nx1, x2 = 1, 56 points_per_interval = 10 steps = (x2 - x1) * points_per_interval + 1 rbf = pd.DataFrame({'x': np.linspace(x1, x2, steps)}) alpha = 1.2 # higher values broaden the hump m_ = 14 rbf = rbf.assign(y=np.exp(-1 * (rbf.x - m_) ** 2 / alpha)) chrt = altair_ts_scatter(rbf, 'x', 'y', 'x') ![[single_hump 1.png]]\nProposed procedure:\nDetermine the highest multiple of $m$ from the range of the data; e.g., if we have two years of data and we want a monthly RBF, the multiple is 24. Create an array for each multiple of $m$, starting one time step after the end of the preceding array Concatentate the arrays into one RBF. def rbf_builder(positions: np.ndarray, period: int = 7, alpha: float = 1.2, points_per_interval: int = 1, ): \"\"\"For the range of the sequence, produce a radial basis function (RBF) comprising smooth peaks around all multiples within a chosen period. The multiples are located where the modulo of the position (time) values and the chosen period are zero. The value of the multiple is equal to the input position array at those locations. For each of those locations and associated values, an RBF is formed by subtracting the value from the position array, as the exponent will evaluate to `1` when its argument is zero. Each RBF (one per period multiple present in the data) is stored in a separate array, which are collected in a list and stacked into a 2D array. The final step, summing vertically over the 2D aray, provides a single RBF with multiple humps--the form we need to include in a linear regression. Parameters ---------- positions Position (time) values associated with a sequence of observations. period Number of sequence or time points (or rows) in the series that define a putative characteristic of the sequence. `7` implies weekly periodicity if data were recorded daily. The period by itself has no inherent meaning; it is always in relation to the data structure (spacing of observations). alpha Width of the humps; higher is wider. points_per_interval Always one, except when unit testing with synthetic data using `numpy.linspace`. \"\"\" rbf_segments = [] # 0 index pulls array out of tuple for m in np.where(np.fmod(positions, period) == 0)[0]: segment = np.exp(-(positions - positions[m]) ** 2 / alpha) rbf_segments.append( segment) # ['rbf_' + str(int(m/points_per_interval))] = segment return pd.DataFrame({'x': positions, 'rbf_' + str(period): np.sum( np.vstack(rbf_segments), axis=0 )}) ![[multi_humps.png]]\nNote the last hump is half cutoff, which is probably appropriate to avoid extending beyond the scope of the data. It’s conceivable we might want RBF with half humps, if something happens mostly on Fridays, sometimes on Thursday, rarely on Wednesdays, but never on Saturdays.\nThe width of the humps, controlled by hyperparameter $\\alpha$, should be tuned or at least dialed into a sensible expectation. In the example above, $\\alpha=1.2$ allows for about $\\pm 2$ days. Warmerdam mentioned Evol, a library to define a complex algorithm in a composable way (sounds like a kindred spirit to patsy). Compare the above function to sklego.preprocessing.RepeatingBasisFunction.\nWe have a function that creates an RBF that peaks every $m^\\text{th}$ instance of a sequence, sometimes including the zeroth position. To become part of the design matrix $X$, the RBF needs to align congruently to the desired DoW, WoM, etc. that $y$ and other RHS predictors align to.\nThere are probably mutliple ways to do this. Let’s say we have arrays $t$, $y$, and some $X$, including the ordinal encoding of $t$ (.dt.weekday) and the binary variables dow_0, … dow_6. We could\nTell NumPy or pandas to concatenate the RBF starting where the ordinal variable matches the day we want. Or align where RBF=1 to where the right binary variable is 1, which requires an extra step: the binary encoding of the ordinal. We’ll take the first approach, though the second seems to facilitate error checking, since we could test that all rows where 1 should be 1 are the same position in the sequence. Ensure complete coverage of the sequence by the RBF. If the RBF was originally tailored to the length of the sequence, there will be empty leading cells to backfill after merging the RBF to the sequence, unless the DoW happened to be in position 0. This dependency alone motivates the use of pandas.merge in concert with indexed collections (ndarray-\u003e series and DataFrame). When using pandas.merge(how='left'), where the left df is the sequence, there will be no trailing RBF values.\nFor the backfill, count leading nulls, compute RBF at $x=t-i$ for $i=1$ to $n_ {nulls}$, or if the arrays are in a DataFrame and pandas has nulls in the leading rows of the RBF, use the (integer) index for $x$.\ndef rbf_builder(positions: np.ndarray, period: int = 7, alpha: float = 1.2, points_per_interval: int = 1, ) -\u003e np.ndarray: \"\"\"For the range of the sequence, produce a radial basis function (RBF) comprising smooth peaks around all existing multiples of a chosen period. The multiples are located where the modulo of the position (time) values and the chosen period are zero. The value of the multiple is equal to the input position array at those locations. For each of those locations and associated values, an RBF is formed by subtracting the value from the position array, as the exponent will evaluate to `1` when its argument is zero. Each RBF (one per period multiple present in the data) is stored in a separate array, which are collected in a list and stacked into a 2D array. The final step, summing vertically over the 2D aray, provides a single RBF with multiple humps--the form we need to include in a linear regression. We do not need to return the results as a dataframe; a NumPy array may be preferable. Parameters ---------- positions Position (time) values associated with a sequence of observations. period Number of sequence or time points (or rows) in the series that define a putative characteristic of the sequence. `7` implies weekly periodicity if data were recorded daily. The period by itself has no inherent meaning; it is always in relation to the data structure (spacing of observations). alpha Width of the humps; higher is wider. points_per_interval Always one, except when unit testing with synthetic data using `numpy.linspace`. \"\"\" rbf_segments = [] # rbf_segments = {'x': sequence} for m in np.where(np.fmod(positions, period) == 0)[ 0]: # zero index pulls array out of tuple segment = np.exp(-(positions - positions[ m]) ** 2 / alpha) # todo: trim sequence to around m rbf_segments.append( segment) # ['rbf_' + str(int(m/points_per_interval))] = segment return np.sum(np.vstack(rbf_segments), axis=0) def rbf_stitcher(seq: pd.DataFrame, rbf: np.ndarray, m_: int = 7, characteristic: str = 'dow', characteristic_value: int = 4, ) -\u003e pd.DataFrame: \"\"\"Extends regression design matrix X with a radial basis function (RBF), ensuring the RBF peak aligns to the desired positions within the sequence. Parameters ---------- seq Sequence of observations. rbf Radial basis, a function of recurring humps. m_ Period of the RBF. characteristic Name of the sequence or time characteristic. characteristic_value Ordinal value of the characteristic. For example, if the characteristic is the day of the week (DoW) and we want the RBF to peak on Fridays, we have prepared a sequence that includes an ordinal encoding via `pandas.dt.weekday` where DoW = 4 corresponds to Fridays. \"\"\" # Convert RBF into a named Series rbf_name = 'rbf_' + str(m_) + '_' + str(characteristic_value) rbf = pd.Series(rbf, name=rbf_name) # locate first instance where specified time characteristic appears in the sequence delay = seq[seq[characteristic] == characteristic_value].index[0] # Adjust index of RBF rbf.index = rbf.index + delay # Merge the RBF to the sequence seq = seq.merge(rbf, left_index=True, right_index=True, how='left') # Verify alignment -- possible? # Backfill any nulls in the RBF resulting from the index alignment idx_null_rbf = seq[np.isnan(seq[rbf_name])].index seq.loc[idx_null_rbf, rbf_name] = seq.loc[ idx_null_rbf + max( idx_null_rbf) + 2, rbf_name][ ::-1].to_numpy() # verify that the +2 scalar is universal and not dependent on the period m_ return seq Along with alpha, does sequence spacing matter? No. We find that, with $\\alpha=1.2$, $\\pm 1$ day from the characteristic date, the RBF is sizable at just over 0.4, dropping precipitously $\\pm 2$ days to about 0.04. Keeping the spacing fixed, changes to alpha adjust those proportions:\n$\\alpha$ $\\pm 1$ day $\\pm 2$ days 1.5 0.51 0.069 1.2 0.43 0.036 0.8 0.29 0.007 0.4 0.082 $4.5 \\cdot 10^{-5}$ Choosing alpha is a two step process. First, minimize forecast error. Second, look at the value of the tuned RBF around peak time points. Consider the unit test case where the signal is elevated on or around Fridays. If alpha of 1.2 is, to a first cut, optimal, it implies that for every $\\beta$ dollars repeatedly paid on Friday, there tends to be $0.40 $\\cdot \\beta$ paid on either Thursday or Saturday, as the coefficient for the RBF will weigh its values. Unless there is a clear reason to reject those proportions, driven by alpha and the minimization of the chosen error metric, keep alpha as is.\nWhen the RBF’s shape (alpha) is chosen this way, we apply an objective basis to attenuate the main effect (payments recurring on Fridays). We can assume that coefficient for dow_4 would have otherwise been underestimated, while that of dow_3 and/or dow_5 (if present) would be overestimated. To verify this intuition, observe beta as alpha shrinks; it should converge to the beta for the corresponding binary variable.\nGiven Friday is the last business day of the week, that RBF maybe should be asymmetrical (to the left), while that for Monday should be asymmetrical (on the right). We are simply trying to obtain both a good fit (low error) and insight through meaningful betas.\nIt is not necessary for the RBF to be super smooth over a fine grid, because the values at the key time points will be the same. Substeps just enhance how the RBF looks by itself, in method documentation (it is unlikely to ever be exposed to the client).\nDeploy the RBF to the artificial time series with signal boosted every Friday Using the statsmodels.tsa.ar_model.AutoReg, disabling seasonal, and adding the RBF as an exog variable:\nauto_reg = AutoReg(tsrbf.y, missing='raise', lags=2, trend='t', seasonal=False, # period=7, exog=tsrbf.rbf_7_4, old_names=False, ) auto_reg1 = auto_reg.fit() tsrbf.loc[:, 'y_hat'] = auto_reg1.predict() pprint(auto_reg1.params) trend 0.001264 y.L1 - 0.119650 y.L2 0.141311 rbf_7_4 2.158667 The periodic effect is clearly captured, with less amplitude compared to the AR seasonal components due to attenuation. Expect higher error as a cost of accommodating variance in the periodicity. We might prove these phenomena by computing the MAPE of each fit, with and without such variance.\n",
  "wordCount" : "5004",
  "inLanguage": "en",
  "datePublished": "2023-01-08T15:18:18-05:00",
  "dateModified": "2023-01-08T15:18:18-05:00",
  "author":{
    "@type": "Person",
    "name": "Aaron Slowey"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://drwaterx.github.io/til/posts/practical_primer_ts/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Aaron's D4ta blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://drwaterx.github.io/til/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://drwaterx.github.io/til/" accesskey="h" title="Aaron&#39;s D4ta blog (Alt + H)">Aaron&#39;s D4ta blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://drwaterx.github.io/til/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://drwaterx.github.io/til/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Explainable insights from linear regression of time series
    </h1>
    <div class="post-meta"><span title='2023-01-08 15:18:18 -0500 EST'>January 8, 2023</span>&nbsp;·&nbsp;Aaron Slowey

</div>
  </header> 
  <div class="post-content"><p>This post is under construction, with missing graphs and unbaked LaTax math.</p>
<p>It&rsquo;s a cliche that linear models are &ldquo;explainable.&rdquo;  And yet, when we
attempt to produce insights that are salient to business, and produce them
from the kind of data representing, let&rsquo;s say, tens of thousands of cases,
you will quickly find characteristics of the data that appreciably erode the
veracity and salience of supposed insights.</p>
<p>This is especially the case when applying canned routines in general, and
I&rsquo;ve found, time series &lsquo;forecasting&rsquo; packages in particular.  At no fault
of their developers, such packages are riddled with potential user missteps,
since they abstract away a lot of the
details of how data are prepared for modeling.  The fidelity between the
temporal structure of the time series and the parameters of the model are
one of the more reliable missteps one can take.</p>
<p>Packages like <code>statsmodels. tsa</code> are workhorses, but do not check, for instance, whether a daily time
series contains only business days, while the user has specified a
&lsquo;seasonality&rsquo; period of 7.  But when I started using it, I was not sure if
it did or not, and so I created artificial data with known structural
infidelities and effects and observed how <code>statsmodels</code> responded, and what
distortions ensued.  This post is a recounting of some of those experiments.</p>
<p>The following covers mostly <em>in-sample</em> deconstruction of temporally
sensitive effects that can be applied to a variety of problems, including
forecasting.  I mention this because in my work at least, the goal is not
just to predict the future but understand temporal patterns and
relationships, since capacity is inextricably linked to maintenance costs,
failure risk, and other things that <em>really</em> matter in business.</p>
<p>We denote a time series context with some additional subscripts:
$$y_t = \alpha + \sum_{i=1}^m \beta_i x_{i,t} + \epsilon_t$$
The properties of variables that constitute $x$ determine what kind of time
series regression we perform.</p>
<ul>
<li>An auto-regression model includes up to $p$ lags: $x_{t-p}, \ldots, x_{t-1}$</li>
<li>A linear trend is included by $x_{1, t} = t$; assuming equally spaced
observations, $t$ would be <code>np.linspace(1, T)</code></li>
<li>Day of week is achieved by having one binary variable for all but one day;
i.e., $x_{i, t}=1$ if the observation occurs on a particular day and zero
otherwise. For any categorical variable having $k$ unique values, include
$k-1$ binary variables into the model. So if we leave out Sunday, $x_{Monday,
t}$ measures the effect of Monday on $y$ <em>compared to the effect of Sunday</em>.</li>
<li>Spike: A dummy variable that is 1 in a specific period, zero before and after</li>
<li>Step: A dummy variable zero up to a point, 1 from that point on. Related is a
change in slope.</li>
</ul>
<p>As with <code>OLS</code>, you can apply statsmodels&rsquo; <code>.summary()</code> method to the fitted
model object, as well as <code>.plot_predict(start=720, end=840)</code>.</p>
<p>The &rsquo;errors&rsquo; should</p>
<ul>
<li>Have mean zero</li>
<li>Not be auto-, or serially, correlated; Breusch-Godfrey or Lagrange Multiplier
test, in which a small <code>p-value</code> is bad (significant autocorrelation remains).</li>
<li>Unrelated to the predictors</li>
<li>Be normally distributed with a constant variance</li>
</ul>
<p><code>.plot_diagnostics()</code> provides some of these diagnostics.</p>
<p><code>statsmodels.tsa</code> has multiple methods for time series
analysis/regression/forecasting. Each term has a different connotation,
depending on how you deploy them. We do not have to use <code>.tsa</code> methods to model
sequence data; multivariate linear regression with univariate lags and time
characteristic variables could achieve roughly the same model. A variety of
considerations may determine the choice of model class, such as simply being
able to report that you used a certain time series analysis package.</p>
<p>In any case, we are tackling the challenge of building a linear model with
familiar performance criteria. The most profound difference is that the
observations are possibly auto-correlated, not I.I.D., but this may &rsquo;normalize&rsquo;
out by simply including lags and time characteristics (seasonal components).</p>
<p>A good starting point is the <code>AutoReg</code> class of  <code>statsmodels.tsa.ar_model</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> statsmodels.tsa.api <span style="color:#f92672">import</span> acf, graphics, pacf
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> statsmodels.tsa.ar_model <span style="color:#f92672">import</span> AutoReg, ar_select_order
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>auto_reg <span style="color:#f92672">=</span> AutoReg(data,
</span></span><span style="display:flex;"><span>                   lags<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,  <span style="color:#75715e"># AR(3)</span>
</span></span><span style="display:flex;"><span>                   seasonal<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                   period<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                   )
</span></span><span style="display:flex;"><span>auto_reg0 <span style="color:#f92672">=</span> auto_reg<span style="color:#f92672">.</span>fit()
</span></span></code></pre></div><p><a href="https://www.statsmodels.org/dev/examples/notebooks/generated/autoregressions.html?highlight=ar_select_order">Worked example</a>
in the <code>statsmodels</code> documentation that fails to clearly show how each component
manifests, and exactly what parameters affect the fit. That ambiguity ends here.</p>
<p>An overarching question is &ndash; to what extent do <code>statsmodels</code> implementations
include utilities that recognize and utilize <code>datetimes</code>? The work below
suggests not at all, despite some warning or errors when <code>seasonal=True</code>,
but <code>period</code> is unspecified. To obtain expected behavior from statistical
learning algorithms, it is crucial to know and potentially modify the sequential
structure (spacing) of data, because there do not appear to be intelligent
checks and automated cleaning processes. Other key questions include</p>
<ul>
<li>For example, $m=52$, unless <code>tsa</code> interprets datetime values intelligently,
only implies a weekly periodicity if there are $7\cdot52$ rows of data.</li>
<li>What if we have $T=1.5$ years of data; haven&rsquo;t seen any caution to carefully
compute the period as $m=p\cdot\frac{52}{q} \cdot T$, where p and q define the
period of interest</li>
<li>There are a few days missing?</li>
<li>What if the data lack Saturdays and Sundays, as with <code>BOLT</code> data?</li>
<li>Does the data need to be processed to ensure there are 7 days per week, 52
weeks per year, imputing zeroes where needed?</li>
</ul>
<p>To begin, create artificial data with known patterns. Create one year of daily
timestamps and initialize the observations with random numbers $\in (0, 1)$. For
other possibilities, see also <code>sklego.datasets.make_simpleseries</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> statsmodels.tsa.ar_model <span style="color:#f92672">import</span> AutoReg, ar_select_order
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>days <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#e6db74">&#39;2022-01-01&#39;</span>, <span style="color:#e6db74">&#39;2023-01-01&#39;</span>, dtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;datetime64[D]&#39;</span>)
</span></span><span style="display:flex;"><span>print(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;There are </span><span style="color:#e6db74">{</span>len(days)<span style="color:#e6db74">}</span><span style="color:#e6db74"> days in the year 2022 (start </span><span style="color:#e6db74">{</span>days<span style="color:#f92672">.</span>min()<span style="color:#e6db74">}</span><span style="color:#e6db74">; end </span><span style="color:#e6db74">{</span>days<span style="color:#f92672">.</span>max()<span style="color:#e6db74">}</span><span style="color:#e6db74">).&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ts <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;t&#39;</span>: days,  <span style="color:#75715e"># np.linspace(1, 100, 100)</span>
</span></span><span style="display:flex;"><span>                   <span style="color:#e6db74">&#39;y&#39;</span>: np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>random(len(days))}
</span></span><span style="display:flex;"><span>                  )
</span></span></code></pre></div><p>![[professional/know_how/stat_modeling/attachments/visualization.png]]</p>
<p>Encode a time characteristic, such as day of the week (dow) and boost the signal
on certain days (or weeks, etc.). Here, we spike the signal on Fridays. Then we
play with the <code>seasonal</code> and <code>period</code> parameters.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>loc[:, <span style="color:#e6db74">&#39;dow&#39;</span>] <span style="color:#f92672">=</span> ts<span style="color:#f92672">.</span>t<span style="color:#f92672">.</span>dt<span style="color:#f92672">.</span>weekday
</span></span><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>y <span style="color:#f92672">=</span> ts<span style="color:#f92672">.</span>y <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>where(ts<span style="color:#f92672">.</span>dow <span style="color:#f92672">==</span> <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>auto_reg <span style="color:#f92672">=</span> AutoReg(ts<span style="color:#f92672">.</span>y,
</span></span><span style="display:flex;"><span>                   lags<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>                   trend<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;t&#39;</span>,
</span></span><span style="display:flex;"><span>                   seasonal<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                   period<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                   )
</span></span><span style="display:flex;"><span>auto_reg0 <span style="color:#f92672">=</span> auto_reg<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>loc[:, <span style="color:#e6db74">&#39;y_hat&#39;</span>] <span style="color:#f92672">=</span> auto_reg0<span style="color:#f92672">.</span>predict()
</span></span><span style="display:flex;"><span>c2 <span style="color:#f92672">=</span> altair_ts_line(ts, <span style="color:#e6db74">&#39;t&#39;</span>, <span style="color:#e6db74">&#39;y_hat&#39;</span>, <span style="color:#e6db74">&#39;t&#39;</span>)
</span></span><span style="display:flex;"><span>(c0 <span style="color:#f92672">+</span> c2)<span style="color:#f92672">.</span>add_selection(pan_zoom)
</span></span></code></pre></div><p>With <code>seasonal=False</code>, we obtain an upwardly trending oscillation:
![[professional/know_how/stat_modeling/attachments/visualization (1).png]]</p>
<p>Enable <code>seasonal</code>, and we get the expected level baseline with weekly peaks:
<strong>Exhibit A</strong>
![[professional/know_how/stat_modeling/attachments/visualization (2).png]]</p>
<p>If we set <code>period=365</code>, we get
a <code>ValueError: The model specification cannot be estimated. The model contains 370 regressors (1 trend, 365 seasonal, 4 lags) but after adjustment for hold_back and creation of the lags, there are only 361 data points available to estimate parameters.</code></p>
<p>And if we set to a feasible, but wrong value &ndash; <code>period=30</code>  &ndash; we will get a
somewhat better result, than without any periodicity, but clearly missing the
effect:
![[professional/know_how/stat_modeling/attachments/visualization (4).png]]</p>
<p>Interestingly, if we increase <code>lags=7</code> to include the weekly effect, we get
almost as good a model as with seasonal terms:</p>
<pre tabindex="0"><code>auto_reg = AutoReg(ts.y,
                   lags=7,
                   trend=&#39;t&#39;,
                   seasonal=False,
                   period=7)
</code></pre><p>![[professional/know_how/stat_modeling/attachments/visualization (5).png]]</p>
<p>Any number of lags above seven, and we see no improvement. Although not shown,
the model with <code>lags=7</code> and <code>seasonal=True</code> with <code>period=7</code> looks identical to
the  <code>seasonal=True</code>, <code>period=7</code> model with <code>lags=4</code> above, suggesting that the
$x_{t-p}$ and $s_d$ terms are collinear.</p>
<p><code>statsmodels.tsa.ar_model.AutoReg</code> interprets <code>period=7</code> as the <em>longest step</em>
from one data point to the next in the dataframe; shorter steps from 1 to $p-1$
are also included. We think that something happens every 7th observation in the
sequence, and whether we like it or not,  <code>AutoReg</code> checks whether anything
happens on shorter cadences. As discussed in detail below, whether those <em>steps</em>
correspond to a meaningful time interval or period depends on the structure of
the sequence.</p>
<p>Look at the coefficients by applying the <code>.params</code> method to the fitted model
object; e.g., with <code>lags=2</code>, <code>seasonal=True</code>, and <code>period=7</code>:
![[Pasted image 20221003171824.png]]</p>
<p>Note that with <code>period</code> and <code>lags</code> set to an integer, multiple terms are
included up to that value: e.g., $[1, \text{lags}]$. Unlike <code>period</code>, you may
provide a list of integers for <code>lags</code>, in which case <em>only</em> those lags are
included. As expected, we find <code>seasonal.6</code> coefficient to be much higher than
those of narrower periodicities. It&rsquo;s also no accident that seasonal components
0-5&rsquo;s coefficients are <em>similar</em> to each other. We will investigate how this
model responds to data with multiple periodicities.</p>
<p>Continuing on with sanity checks, no matter the length of the sequence, as long
as there are more data points than <code>lags</code> (and other parameters), the model will
fit properly. Here, we have data from Jan through March 2022.
![[visualization (6).png]]</p>
<p><code>statsmodels.tsa</code> does not require the time or sequence index to be of
a <code>datetime</code> dtype. Replacing datetime values by integers, we obtain the same
result (not shown). But note that <code>AutoReg</code> is not being explicitly given a
sequence or time variable; it is implicit in the <code>pandas.Series</code> index of <code>ts.y</code>
, so the algorithm is unaware of the change in the time column <code>ts.t</code> . If we
remove a small number of points at random such that there are gaps in the index,
the model falls apart (not shown). Can we make the seasonal regression algorithm
aware that observations are made on calendar days?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>points <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>idx_mask <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">0</span>, len(ts), points)
</span></span><span style="display:flex;"><span>ts <span style="color:#f92672">=</span> ts[<span style="color:#f92672">~</span>ts<span style="color:#f92672">.</span>index<span style="color:#f92672">.</span>isin(idx_mask)]
</span></span></code></pre></div><p>Incidentally, avoid <code>df.sample(frac=0.9)</code>, as it shuffles the rows.</p>
<p>Setting the index with the datetime-formatted values (maintaining the five
randomly placed gaps) leads
to <code>ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.</code>
The predictions from <code>.predict()</code> are all null.</p>
<p>What matters is a logical correspondence between <code>period</code> and the frequency of
the data as presented by their sequence in the array or DataFrame. Let&rsquo;s
say <code>period=7</code>; if the frequency is unspecified, the algorithm just considers if
a data point six steps from the current point tends to be higher, lower, or
about the same as the current point. If the data happen to be observations
recorded every nanosecond with a perturbation every 13 ns, <code>period=13</code> should
fit that sequence nicely. This naive behavior is helpful for modeling
observations that occur with a regularity that is meaningful, if not in a
temporal way. For example, every fourth trip to buy groceries, the family goes
to Costco, not Trader Joe&rsquo;s. But it poses a problem for incomplete and irregular
sequences when effects pertain to certain fixed time qualities.</p>
<p>When <code>.set_index('dt_col')</code> involves a datetime column, we obtain
a <code>DateTimeIndex</code> with <code>freq=None</code>, which <code>statsmodels.tsa.ar_model</code> is
complaining about. We can specify the frequency</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ts <span style="color:#f92672">=</span> ts<span style="color:#f92672">.</span>set_index(<span style="color:#e6db74">&#39;t&#39;</span>)<span style="color:#f92672">.</span>asfreq(<span style="color:#e6db74">&#39;d&#39;</span>)
</span></span></code></pre></div><p>Having reproduced the result shown in Exhibit A with a complete data set indexed
in this way, we return to the case where points are randomly missing; remove
them <em>prior to</em> setting the datetime index and frequency. Here, we introduce a
potential problem. As an aside, <code>.asfreq('B')</code> sets an index to daily business
day. <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.asfreq.html?highlight=asfreq#pandas.DataFrame.asfreq">More</a> <code>.asfreq</code>
can be applied to a DataFrame; it will return the DataFrame &ldquo;reindexed to the
specified frequency.&rdquo;
Meaning the &ldquo;original data conformed to a new index with the specified
frequency.&rdquo;  In this case, to conform to daily frequency, rows of <code>nan</code> are
placed where time points were missing. Before and after applying <code>.asfreq('d')</code>:
![[Pasted image 20221004101943.png]]
![[Pasted image 20221004102013.png]]</p>
<p><code>AutoReg</code> will raise a <code>MissingDataError: exog contains inf or nans</code>, resolvable
by including <code>missing='drop'</code>. And yet even though we have a <code>DatetimeIndex</code>
with <code>freq='D'</code>, we still get
a <code>ValueWarning: A date index has been provided, but it has no associated frequency information</code>
. Instead of a <code>DatetimeIndex</code> with <code>.asfreq('d')</code>, we can try a <code>PeriodIndex</code>,
a subclass of <code>Index</code> that is regularly spaced:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>set_index(<span style="color:#e6db74">&#39;t&#39;</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>index <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DatetimeIndex(ts<span style="color:#f92672">.</span>index)<span style="color:#f92672">.</span>to_period(<span style="color:#e6db74">&#39;D&#39;</span>)
</span></span></code></pre></div><pre tabindex="0"><code>PeriodIndex([&#39;2022-01-01&#39;, &#39;2022-01-02&#39;, &#39;2022-01-03&#39;, &#39;2022-01-04&#39;,
             &#39;2022-01-05&#39;, &#39;2022-01-06&#39;, &#39;2022-01-07&#39;, &#39;2022-01-08&#39;,
             &#39;2022-01-09&#39;, &#39;2022-01-10&#39;,
             ...
             &#39;2022-12-22&#39;, &#39;2022-12-23&#39;, &#39;2022-12-24&#39;, &#39;2022-12-25&#39;,
             &#39;2022-12-26&#39;, &#39;2022-12-27&#39;, &#39;2022-12-28&#39;, &#39;2022-12-29&#39;,
             &#39;2022-12-30&#39;, &#39;2022-12-31&#39;],
            dtype=&#39;period[D]&#39;, name=&#39;t&#39;, length=360, freq=&#39;D&#39;)
</code></pre><p>We still have gaps in the time series, but no <code>nan</code> have been inserted:
![[Pasted image 20221004104608.png]]</p>
<p>It is unnecessary to include <code>missing='drop'</code> in <code>AutoReg()</code>, since the data has
no missing values (it is probably good practice to include <code>missing='raise'</code> as
a check).  <code>.fit()</code> runs and <code>.predict()</code> returns values without alterring the
input data structure: it still has a <code>PeriodIndex</code>:
![[Pasted image 20221004105317.png]]</p>
<p>Did the model fit well? While the <code>PeriodIndex</code> facilitated the fit, it
complicates plotting with Altair. Assuming the index needs to be reset into a
column, a  <code>PeriodIndex</code>  resets to a column of <code>'period[D]' </code>dtype, and this
leads to a <code>TypeError</code>. After fitting the model with <code>PeriodIndex</code>-ed data,
reformat the index:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>index <span style="color:#f92672">=</span> ts<span style="color:#f92672">.</span>index<span style="color:#f92672">.</span>to_timestamp()
</span></span></code></pre></div><p>You will lose the <code>freq</code> and have a <code>DatetimeIndex</code> once again. Then reset _
that_ index and plot as usual.
![[professional/know_how/stat_modeling/attachments/visualization (2) 1.png]]
![[Pasted image 20221004121816.png]]
Our model did not capture the Friday signal as before, presumably because it
naively assumed every $7\cdot n^{th}$ point was Friday, ignoring the days
skipped in the index. Note how the parameters&rsquo; seasonal components are written
as <code>s(1, 7)</code>, whereas before it was <code>seasonal.0</code>. The connotation is that we&rsquo;re
capturing effects that occur every 1st of 7 days?</p>
<p>We&rsquo;ve tried two ways to structure our data such that <code>statsmodels.tsa</code> is aware
of timing. But this data transformation did not apparently raise such awareness,
as the model failed to fit the elevated values on Fridays. It could not even use
the <code>DateTimeIndex</code> with a daily frequency. All of these observations suggest
that what ultimately matters to <code>statsmodels.tsa</code> is the numerical index of the
table; row 6 means Friday, whether the Tuesday before is missing or not (in
which case Friday is actually in row 5). To the machine, they are all just row
indices, not days.</p>
<p>Notice how the model suggests a stronger signal around day 7, adjoined by
expectation of signal quite a bit before; the behavior is smeared or muddled.
Absence of even a handful of time points throws off the periodicity of this time
series.</p>
<p>As for the datetime, period, and all that functionality in pandas&hellip;it serves
other uses, such as resampling, aggregations, synthesizing data, and more.</p>
<p>This is a practical problem, as there are bound to be missing time points,
either random or systematic (e.g., transactions on business days only). A path
forward would be to have all dates present and put zeroes where no transactions
occurred (perhaps packages like <code>tbats</code> do this under the hood?). For some
systematic effects like weekend dormancy, the model should fit coefficients on
those days accordingly; i.e., $\beta_{s(5)}$ and $\beta_{s(6)}$ should be close
to zero. Holidays are another systematic effect we would need an exogenous
binary variable to capture to avoid errors in the seasonal component estimates.
Lastly, randomly occurring times without transactions will just have to be
factored in by $\beta_{s(t)}$ to the extent they occur, which is rational.</p>
<p>Using <code>.asfreq</code> to conform a daily time series of 365 points minus 10 removed at
random to a <code>DatetimeIndex</code>-ed dataframe with <code>freq='D'</code>, we get a good fit.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ts <span style="color:#f92672">=</span> ts<span style="color:#f92672">.</span>asfreq(<span style="color:#e6db74">&#39;d&#39;</span>)
</span></span><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>auto_reg <span style="color:#f92672">=</span> AutoReg(ts<span style="color:#f92672">.</span>y,
</span></span><span style="display:flex;"><span>                   missing<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;raise&#39;</span>,
</span></span><span style="display:flex;"><span>                   lags<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>                   trend<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;t&#39;</span>,
</span></span><span style="display:flex;"><span>                   seasonal<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                   period<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                   old_names<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                   )
</span></span><span style="display:flex;"><span>auto_reg0 <span style="color:#f92672">=</span> auto_reg<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>ts<span style="color:#f92672">.</span>loc[:, <span style="color:#e6db74">&#39;y_hat&#39;</span>] <span style="color:#f92672">=</span> auto_reg0<span style="color:#f92672">.</span>predict()
</span></span></code></pre></div><p>![[Pasted image 20221004163931.png]]</p>
<p>The coefficient 2.37 is lower than 2.55 for the fit of the complete dataset,
which suggests that some Fridays may have been zeroed out by the data
preparation. But as long as such a random effect is not too prevalent, the
autoregression should provide reasonable results. Here the incidence of '
missing&rsquo; days is about 3%.</p>
<p>Another method may allow discrete seasonality, rather than the
inclusive/cumulative sort employed by <code>AutoReg</code>. The choice calls for a design
principle:</p>
<ul>
<li>Autoregression plus seasonality</li>
<li>Hand-derived features</li>
<li>Both: what are each capturing?</li>
</ul>
<p>For example, no matter how many time points are absent, if we encode Friday
correctly, that feature will light up on this artificial data set, and so is a
more reliable approach than an autoregressive seasonality model (alone). Since
it cannot include custom features, the <code>AutoReg</code> class is more suitable for EDA
than deployment as an estimator or forecasting service.</p>
<blockquote>
<p>No matter what method we choose, we need to verify, using synthetic data, that
the choice and its parameters is congruent with the <em>structure</em> of our sequence
data.</p>
</blockquote>
<p>What if the signal boost occurred <em>every other</em> Friday? s(7,7) = 1.5, while
other seasonal variables are similar to before, although a bit elevated (0.51 to
0.56); what seems to have happened is a halving of the Friday effect. The model
is unaware of what week each transaction occurred.
![[visualization (8).png]]</p>
<p>Increasing <code>period</code> to 15 leads to worse results, probably due to how larger
interval effects do not consistently align to even or odd Fridays across months
of the year. In sum, if we believe such specific periodic effects are there, or
conversely want to probe for them, we should simply encode it as a binary
variable consistent with how the data are prepared. The coefficients on those
variables from the regression provide the evidence. From there, we can decide
whether to remove extraneous variables, to improve our estimates of the
remaining effects. To probe for suprises in production, we may deploy the more
inclusive, though, problematic (collinearity, etc.) alongside the &lsquo;selected&rsquo;
model.</p>
<p>Up until this point, binary variables and periodic components in the <code>AutoReg</code>
model class produce spiky or jagged looking forecasts. The variability common to
real world data&ndash;a recurring transaction happening <em>around</em>, rather than
consistently precisely <em>on</em>, a particular day, attenuates the weight (
coefficient) of the effect(s), as it should. However, the attenuation may be
unpredictably unstable, because we&rsquo;re asking the model to size a discrete effect
that may never exist. Instead, we can relax the effect to have some
flexibility&ndash;a day or two before or after Friday, for instance. We just need to
change the Dirac deltas to humps, or radial basis functions.</p>
<p>In a 2018 Pydata London <a href="https://www.youtube.com/watch?v=68ABAU_V8qI">talk</a>,
Vincent Warmerdam spoke about linear models, including using RBFs. See also his
talk <a href="https://www.youtube.com/watch?v=Z8MEFI7ZJlA">How to Constrain Artificial Stupidity</a>
. He has co-led initiatives including <code>evol</code> and <code>scikit-lego</code>.</p>
<p>Most web searches go to RBF kernels for SVMs or RBF neural networks, neither of
which are tactically relevant here.  <code>SciPy</code> has an RBF fitting routine; closer
perhaps, but still not in-line with our objective to produce artificial peaks as
regression predictors; that is, to <em>generate</em> artificial peaks and let the
regression weigh its importance and tune their widths, <em>given the presence</em> of
other behaviorally (temporally) specific effects on the RHS. The math that
fulfills this purpose is $$\phi(x_i) = \text{exp}
\Big[-\frac{1}{2\alpha} (x-m_i)^2 \Big]~ \forall ~\text{week, month, or} \dots$$
where $$
m_i=\begin{cases}
1, &amp; \text{if}\ x ~ \text{mod}~ im_1=0 \
0, &amp; \text{otherwise}
\end{cases}
$$
and $i$ ranges from 1 to however many instances of period $m_1$ exist in the
data; for instance, if $m_1=7$, and we have 56 days of data,
$i\in[1, 2, 3, 4,5 ,6, 7, 8]$ and $m \in [7, 14, 21, 28, 35, 42, 49, 56]$.
Recall the $\text{mod}$, or modulo, is the <em>remainder</em> that, alongside the _
quotient_, is an answer to a division of a <em>dividend</em> by a <em>divisor</em>. For
example, <code>14 mod 3 = 2</code>; <code>9 mod 3</code> and <code>121 mod 11</code> are zero.</p>
<p>Note $m$ is the <em>period</em> as defined in relation to the sequence structure;
e.g., <code>7</code> implies weekly periodicity if data are daily; <code>6</code> would imply a
semiannual periodicity of monthly data and annual periodicity for bimonthly
data.</p>
<p>The RBF should</p>
<ul>
<li>Peak at <code>1</code> at the characteristic points in the sequence and</li>
<li>Smoothly decay to zero on either side.</li>
</ul>
<p>The exponential will only evaluate to <code>1</code> when the quantity in the brackets is
zero; i.e., when $x = m_i$; $i$ denotes the $i^{\text{th}}$ week, month, etc.
within the data&rsquo;s boundaries. For weekly periodicity, the RBF evaluates to 1
when $x \in [7, 14, 21, &hellip;]$. While it is easy to perform this calculation for
one value of $m$ (see below), to get the other humps we need, we need to also
subtract <code>14</code> and so on.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x1, x2 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">56</span>
</span></span><span style="display:flex;"><span>points_per_interval <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>steps <span style="color:#f92672">=</span> (x2 <span style="color:#f92672">-</span> x1) <span style="color:#f92672">*</span> points_per_interval <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>rbf <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;x&#39;</span>: np<span style="color:#f92672">.</span>linspace(x1, x2, steps)})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.2</span>  <span style="color:#75715e"># higher values broaden the hump</span>
</span></span><span style="display:flex;"><span>m_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">14</span>
</span></span><span style="display:flex;"><span>rbf <span style="color:#f92672">=</span> rbf<span style="color:#f92672">.</span>assign(y<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">*</span> (rbf<span style="color:#f92672">.</span>x <span style="color:#f92672">-</span> m_) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">/</span> alpha))
</span></span><span style="display:flex;"><span>chrt <span style="color:#f92672">=</span> altair_ts_scatter(rbf, <span style="color:#e6db74">&#39;x&#39;</span>, <span style="color:#e6db74">&#39;y&#39;</span>, <span style="color:#e6db74">&#39;x&#39;</span>)
</span></span></code></pre></div><p>![[single_hump 1.png]]</p>
<p>Proposed procedure:</p>
<ol>
<li>Determine the highest multiple of $m$ from the range of the data; e.g., if we
have two years of data and we want a monthly RBF, the multiple is 24.</li>
<li>Create an array for each multiple of $m$, starting one time step after the
end of the preceding array</li>
<li>Concatentate the arrays into one RBF.</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rbf_builder</span>(positions: np<span style="color:#f92672">.</span>ndarray,
</span></span><span style="display:flex;"><span>                period: int <span style="color:#f92672">=</span> <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                alpha: float <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.2</span>,
</span></span><span style="display:flex;"><span>                points_per_interval: int <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                ):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;For the range of the sequence, produce a radial basis function (RBF) comprising smooth peaks around all multiples within a chosen period.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    The multiples are located where the modulo of the position (time) values and the chosen period are zero.  The value of the multiple is equal to the input position 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    array at those locations.  For each of those locations and associated values,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    an RBF is formed by subtracting the value from the position array, as the 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    exponent will evaluate to `1` when its argument is zero.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Each RBF (one per period multiple present in the data) is stored in a separate
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    array, which are collected in a list and stacked into a 2D array. The final step, summing vertically over the 2D aray, provides a single RBF with multiple humps--the form we need to include in a linear regression.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ----------
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    positions
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Position (time) values associated with a sequence of observations.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    period
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Number of sequence or time points (or rows) in the series that define a putative characteristic
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        of the sequence. `7` implies weekly periodicity if data were recorded daily. The period by itself 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        has no inherent meaning; it is always in relation to the data structure (spacing of observations).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    alpha
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Width of the humps; higher is wider.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    points_per_interval
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Always one, except when unit testing with synthetic data using `numpy.linspace`.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    rbf_segments <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 0 index pulls array out of tuple</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> np<span style="color:#f92672">.</span>where(np<span style="color:#f92672">.</span>fmod(positions, period) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>)[<span style="color:#ae81ff">0</span>]:
</span></span><span style="display:flex;"><span>        segment <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span>(positions <span style="color:#f92672">-</span> positions[m]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">/</span> alpha)
</span></span><span style="display:flex;"><span>        rbf_segments<span style="color:#f92672">.</span>append(
</span></span><span style="display:flex;"><span>            segment)  <span style="color:#75715e"># [&#39;rbf_&#39; + str(int(m/points_per_interval))] = segment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;x&#39;</span>: positions,
</span></span><span style="display:flex;"><span>                         <span style="color:#e6db74">&#39;rbf_&#39;</span> <span style="color:#f92672">+</span> str(period): np<span style="color:#f92672">.</span>sum(
</span></span><span style="display:flex;"><span>                             np<span style="color:#f92672">.</span>vstack(rbf_segments), axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>                         )})
</span></span></code></pre></div><p>![[multi_humps.png]]</p>
<p>Note the last hump is half cutoff, which is probably appropriate to avoid
extending beyond the scope of the data. It&rsquo;s conceivable we might want RBF with
half humps, if something happens mostly on Fridays, sometimes on Thursday,
rarely on Wednesdays, but never on Saturdays.</p>
<p>The width of the humps, controlled by hyperparameter $\alpha$, should be tuned
or at least dialed into a sensible expectation. In the example above,
$\alpha=1.2$ allows for about $\pm 2$ days. Warmerdam
mentioned <a href="https://evol.readthedocs.io/en/latest/">Evol</a>, a library to define a
complex algorithm in a composable way (sounds like a kindred spirit to <code>patsy</code>).
Compare the above function to <code>sklego.preprocessing.RepeatingBasisFunction</code>.</p>
<p>We have a function that creates an RBF that peaks every $m^\text{th}$ instance
of a sequence, sometimes including the zeroth position. To become part of the
design matrix $X$, the RBF needs to align congruently to the desired DoW, WoM,
etc. that $y$ and other RHS predictors align to.</p>
<p>There are probably mutliple ways to do this. Let&rsquo;s say we have arrays $t$, $y$,
and some $X$, including the ordinal encoding of $t$ (<code>.dt.weekday</code>) and the
binary variables <code>dow_0</code>, &hellip; <code>dow_6</code>. We could</p>
<ol>
<li>Tell NumPy or pandas to concatenate the RBF starting where the ordinal
variable matches the day we want.</li>
<li>Or align where RBF=1 to where the right binary variable is 1, which requires
an extra step: the binary encoding of the ordinal. We&rsquo;ll take the first
approach, though the second seems to facilitate error checking, since we
could test that <em>all</em> rows where 1 should be 1 are the same position in the
sequence.</li>
</ol>
<p>Ensure complete coverage of the sequence by the RBF. If the RBF was originally
tailored to the length of the sequence, there will be empty leading cells to
backfill after merging the RBF to the sequence, unless the DoW happened to be in
position <code>0</code>. This dependency alone motivates the use of <code>pandas.merge</code> in
concert with indexed collections (ndarray-&gt; series and DataFrame). When
using <code>pandas.merge(how='left')</code>, where the left df is the sequence, there will
be no trailing RBF values.</p>
<p>For the backfill, count leading nulls, compute RBF at $x=t-i$ for $i=1$ to $n_
{nulls}$, or if the arrays are in a DataFrame and pandas has nulls in the
leading rows of the RBF, use the (integer) index for $x$.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rbf_builder</span>(positions: np<span style="color:#f92672">.</span>ndarray,
</span></span><span style="display:flex;"><span>                period: int <span style="color:#f92672">=</span> <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                alpha: float <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.2</span>,
</span></span><span style="display:flex;"><span>                points_per_interval: int <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                ) <span style="color:#f92672">-&gt;</span> np<span style="color:#f92672">.</span>ndarray:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;For the range of the sequence, produce a radial basis function (RBF) comprising
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    smooth peaks around all existing multiples of a chosen period.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    The multiples are located where the modulo of the position (time) values and the 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    chosen period are zero.  The value of the multiple is equal to the input position 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    array at those locations.  For each of those locations and associated values,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    an RBF is formed by subtracting the value from the position array, as the 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    exponent will evaluate to `1` when its argument is zero.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Each RBF (one per period multiple present in the data) is stored in a separate
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    array, which are collected in a list and stacked into a 2D array.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    The final step, summing vertically over the 2D aray, provides a single RBF with 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    multiple humps--the form we need to include in a linear regression.  We do not need to
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    return the results as a dataframe; a NumPy array may be preferable.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ----------
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    positions
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Position (time) values associated with a sequence of observations.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    period
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Number of sequence or time points (or rows) in the series that define a putative characteristic
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        of the sequence. `7` implies weekly periodicity if data were recorded daily. The period by itself 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        has no inherent meaning; it is always in relation to the data structure (spacing of observations).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    alpha
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Width of the humps; higher is wider.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    points_per_interval
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Always one, except when unit testing with synthetic data using `numpy.linspace`.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    rbf_segments <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># rbf_segments = {&#39;x&#39;: sequence}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> np<span style="color:#f92672">.</span>where(np<span style="color:#f92672">.</span>fmod(positions, period) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>)[
</span></span><span style="display:flex;"><span>        <span style="color:#ae81ff">0</span>]:  <span style="color:#75715e"># zero index pulls array out of tuple</span>
</span></span><span style="display:flex;"><span>        segment <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span>(positions <span style="color:#f92672">-</span> positions[
</span></span><span style="display:flex;"><span>            m]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">/</span> alpha)  <span style="color:#75715e"># todo: trim sequence to around m</span>
</span></span><span style="display:flex;"><span>        rbf_segments<span style="color:#f92672">.</span>append(
</span></span><span style="display:flex;"><span>            segment)  <span style="color:#75715e"># [&#39;rbf_&#39; + str(int(m/points_per_interval))] = segment</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>vstack(rbf_segments), axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rbf_stitcher</span>(seq: pd<span style="color:#f92672">.</span>DataFrame,
</span></span><span style="display:flex;"><span>                 rbf: np<span style="color:#f92672">.</span>ndarray,
</span></span><span style="display:flex;"><span>                 m_: int <span style="color:#f92672">=</span> <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                 characteristic: str <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;dow&#39;</span>,
</span></span><span style="display:flex;"><span>                 characteristic_value: int <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>                 ) <span style="color:#f92672">-&gt;</span> pd<span style="color:#f92672">.</span>DataFrame:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Extends regression design matrix X with a radial basis function (RBF),
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ensuring the RBF peak aligns to the desired positions within the sequence.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ----------
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    seq
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Sequence of observations.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    rbf
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Radial basis, a function of recurring humps.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    m_
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Period of the RBF.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    characteristic
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Name of the sequence or time characteristic.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    characteristic_value
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Ordinal value of the characteristic.  For example, if the characteristic is
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        the day of the week (DoW) and we want the RBF to peak on Fridays,
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        we have prepared a sequence that includes an ordinal encoding via `pandas.dt.weekday`
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        where DoW = 4 corresponds to Fridays.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Convert RBF into a named Series</span>
</span></span><span style="display:flex;"><span>    rbf_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;rbf_&#39;</span> <span style="color:#f92672">+</span> str(m_) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;_&#39;</span> <span style="color:#f92672">+</span> str(characteristic_value)
</span></span><span style="display:flex;"><span>    rbf <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>Series(rbf, name<span style="color:#f92672">=</span>rbf_name)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># locate first instance where specified time characteristic appears in the sequence</span>
</span></span><span style="display:flex;"><span>    delay <span style="color:#f92672">=</span> seq[seq[characteristic] <span style="color:#f92672">==</span> characteristic_value]<span style="color:#f92672">.</span>index[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Adjust index of RBF</span>
</span></span><span style="display:flex;"><span>    rbf<span style="color:#f92672">.</span>index <span style="color:#f92672">=</span> rbf<span style="color:#f92672">.</span>index <span style="color:#f92672">+</span> delay
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Merge the RBF to the sequence</span>
</span></span><span style="display:flex;"><span>    seq <span style="color:#f92672">=</span> seq<span style="color:#f92672">.</span>merge(rbf, left_index<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, right_index<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, how<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;left&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Verify alignment -- possible?</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Backfill any nulls in the RBF resulting from the index alignment</span>
</span></span><span style="display:flex;"><span>    idx_null_rbf <span style="color:#f92672">=</span> seq[np<span style="color:#f92672">.</span>isnan(seq[rbf_name])]<span style="color:#f92672">.</span>index
</span></span><span style="display:flex;"><span>    seq<span style="color:#f92672">.</span>loc[idx_null_rbf, rbf_name] <span style="color:#f92672">=</span> seq<span style="color:#f92672">.</span>loc[
</span></span><span style="display:flex;"><span>                                          idx_null_rbf <span style="color:#f92672">+</span> max(
</span></span><span style="display:flex;"><span>                                              idx_null_rbf) <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span>, rbf_name][
</span></span><span style="display:flex;"><span>                                      ::<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>to_numpy()
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># verify that the +2 scalar is universal and not dependent on the period m_</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> seq
</span></span></code></pre></div><p>Along with <code>alpha</code>, does sequence spacing matter? No. We find that, with
$\alpha=1.2$, $\pm 1$ day from the characteristic date, the RBF is sizable at
just over 0.4, dropping precipitously $\pm 2$ days to about 0.04. Keeping the
spacing fixed, changes to alpha adjust those proportions:</p>
<table>
<thead>
<tr>
<th style="text-align:left">$\alpha$</th>
<th style="text-align:right">$\pm 1$ day</th>
<th style="text-align:right">$\pm 2$ days</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1.5</td>
<td style="text-align:right">0.51</td>
<td style="text-align:right">0.069</td>
</tr>
<tr>
<td style="text-align:left">1.2</td>
<td style="text-align:right">0.43</td>
<td style="text-align:right">0.036</td>
</tr>
<tr>
<td style="text-align:left">0.8</td>
<td style="text-align:right">0.29</td>
<td style="text-align:right">0.007</td>
</tr>
<tr>
<td style="text-align:left">0.4</td>
<td style="text-align:right">0.082</td>
<td style="text-align:right">$4.5 \cdot 10^{-5}$</td>
</tr>
</tbody>
</table>
<p>Choosing alpha is a two step process. First, minimize forecast error. Second,
look at the value of the tuned RBF around peak time points. Consider the unit
test case where the signal is elevated on or around Fridays. If alpha of 1.2 is,
to a first cut, optimal, it implies that for every $\beta$ dollars repeatedly
paid on Friday, there tends to be $0.40 $\cdot \beta$ paid on either Thursday or
Saturday, as the coefficient for the RBF will weigh its values. Unless there is
a clear reason to reject those proportions, driven by alpha and the minimization
of the chosen error metric, keep alpha as is.</p>
<p>When the RBF&rsquo;s shape (alpha) is chosen this way, we apply an objective basis to
attenuate the main effect (payments recurring on Fridays). We can assume that
coefficient for <code>dow_4</code> would have otherwise been underestimated, while that
of <code>dow_3</code> and/or <code>dow_5</code> (if present) would be overestimated. To verify this
intuition, observe beta as alpha shrinks; it should converge to the beta for the
corresponding binary variable.</p>
<p>Given Friday is the last business day of the week, <em>that</em> RBF maybe should be
asymmetrical (to the left), while that for Monday should be asymmetrical (on the
right). We are simply trying to obtain both a good fit (low error) and insight
through meaningful betas.</p>
<p>It is not necessary for the RBF to be super smooth over a fine grid, because the
values at the key time points will be the same. Substeps just enhance how the
RBF looks by itself, in method documentation (it is unlikely to ever be exposed
to the client).</p>
<h3 id="deploy-the-rbf-to-the-artificial-time-series-with-signal-boosted-every-friday">Deploy the RBF to the artificial time series with signal boosted every Friday<a hidden class="anchor" aria-hidden="true" href="#deploy-the-rbf-to-the-artificial-time-series-with-signal-boosted-every-friday">#</a></h3>
<p>Using the <code>statsmodels.tsa.ar_model.AutoReg</code>, disabling <code>seasonal</code>, and adding
the RBF as an <code>exog</code> variable:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>auto_reg <span style="color:#f92672">=</span> AutoReg(tsrbf<span style="color:#f92672">.</span>y,
</span></span><span style="display:flex;"><span>                   missing<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;raise&#39;</span>,
</span></span><span style="display:flex;"><span>                   lags<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>                   trend<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;t&#39;</span>,
</span></span><span style="display:flex;"><span>                   seasonal<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                   <span style="color:#75715e"># period=7,</span>
</span></span><span style="display:flex;"><span>                   exog<span style="color:#f92672">=</span>tsrbf<span style="color:#f92672">.</span>rbf_7_4,
</span></span><span style="display:flex;"><span>                   old_names<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                   )
</span></span><span style="display:flex;"><span>auto_reg1 <span style="color:#f92672">=</span> auto_reg<span style="color:#f92672">.</span>fit()
</span></span><span style="display:flex;"><span>tsrbf<span style="color:#f92672">.</span>loc[:, <span style="color:#e6db74">&#39;y_hat&#39;</span>] <span style="color:#f92672">=</span> auto_reg1<span style="color:#f92672">.</span>predict()
</span></span><span style="display:flex;"><span>pprint(auto_reg1<span style="color:#f92672">.</span>params)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trend
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0.001264</span>
</span></span><span style="display:flex;"><span>y<span style="color:#f92672">.</span>L1 <span style="color:#f92672">-</span> <span style="color:#ae81ff">0.119650</span>
</span></span><span style="display:flex;"><span>y<span style="color:#f92672">.</span>L2
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0.141311</span>
</span></span><span style="display:flex;"><span>rbf_7_4
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2.158667</span>
</span></span></code></pre></div><p><img loading="lazy" src="/rbf_test1.png" alt="RBF test"  />
</p>
<p>The periodic effect is clearly captured, with less amplitude compared to the AR
seasonal components due to attenuation. Expect higher error as a cost of
accommodating variance in the periodicity. We might prove these phenomena by
computing the MAPE of each fit, with and without such variance.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://drwaterx.github.io/til/tags/modeling/">modeling</a></li>
      <li><a href="https://drwaterx.github.io/til/tags/statsmodels/">statsmodels</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://drwaterx.github.io/til/">Aaron&#39;s D4ta blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
